{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc842a81",
   "metadata": {},
   "source": [
    "# Project MDA (Heatwave data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f334f9aa",
   "metadata": {},
   "source": [
    "## Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7a6377f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "import math\n",
    "import sklearn as sk\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "import math\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Flatten, Dropout\n",
    "from tensorflow import keras\n",
    "from sklearn import linear_model\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9985356",
   "metadata": {},
   "source": [
    "## Importing time series input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73b571de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "COUNTRY_MAPPINGS = {'Belgium':'BE_temperature','Netherlands':'NL_temperature'} # to be continued...\n",
    "MONTH_TO_DAY_MAPPINGS = {'1.0':31,'2.0':28,'3.0':31,'4.0':30,'5.0':31,'6.0':30,'7.0':31,'8.0':31,'9.0':30,'10.0':31,'11.0':30,'12.O':31}\n",
    "\n",
    "def get_avg_temp(year, month, day, duration, country): # ('2003','08','15',4,'Belgium')\n",
    "    \"\"\"\n",
    "    Given a period and country in which a heatwave occurs, return the avg temperature of this period.\n",
    "    \"\"\"\n",
    "    begin_date = str(year) + '-' + str(month) + '-' + str(day) + 'T00:00:00Z'\n",
    "    print(begin_date)\n",
    "    data = pd.read_csv('weather_data.csv')\n",
    "    country = COUNTRY_MAPPINGS[country]\n",
    "    df = data[['utc_timestamp',country]]\n",
    "    #df['utc_timestamp'] = df['utc_timestamp'].astype('string')\n",
    "    begin_index = df.index[df['utc_timestamp'] == begin_date].tolist()[0]\n",
    "    end_index = begin_index + (duration * 24)\n",
    "    heat_wave_temps = df.iloc[begin_index:end_index]\n",
    "    avg_temp = round(heat_wave_temps[country].sum()/len(heat_wave_temps.index),2)\n",
    "    return avg_temp\n",
    "\n",
    "def get_month_to_day(months):\n",
    "    \"\"\"\n",
    "    Returns amount of days in a certain month.\n",
    "    \"\"\"\n",
    "    return [MONTH_TO_DAY_MAPPINGS[str(m)] for m in months]\n",
    "\n",
    "def plot(df_out,column_name):\n",
    "    \"\"\"\n",
    "    Plot a certain column of a certain df.\n",
    "    \"\"\"\n",
    "    x = df_out['Year'].to_numpy()\n",
    "    y = df_out[column_name].to_numpy()\n",
    "    plt.plot(x, y)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04598f9",
   "metadata": {},
   "source": [
    "## Get input time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55f34668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|    |   Year |   amount_heatwaves |   avg_hw_temp |\n",
      "|---:|-------:|-------------------:|--------------:|\n",
      "|  0 |   1980 |                  0 |             0 |\n",
      "|  1 |   1981 |                  0 |             0 |\n",
      "|  2 |   1982 |                  0 |             0 |\n",
      "|  3 |   1983 |                  0 |             0 |\n",
      "|  4 |   1984 |                  0 |             0 |\n",
      "|  5 |   1985 |                  0 |             0 |\n",
      "|  6 |   1986 |                  0 |             0 |\n",
      "|  7 |   1987 |                  0 |             0 |\n",
      "|  8 |   1988 |                  0 |             0 |\n",
      "|  9 |   1989 |                  0 |             0 |\n",
      "| 10 |   1990 |                  0 |             0 |\n",
      "| 11 |   1991 |                  0 |             0 |\n",
      "| 12 |   1992 |                  0 |             0 |\n",
      "| 13 |   1993 |                  0 |             0 |\n",
      "| 14 |   1994 |                  0 |             0 |\n",
      "| 15 |   1995 |                  0 |             0 |\n",
      "| 16 |   1996 |                  0 |             0 |\n",
      "| 17 |   1997 |                  0 |             0 |\n",
      "| 18 |   1998 |                  0 |             0 |\n",
      "| 19 |   1999 |                  0 |             0 |\n",
      "| 20 |   2000 |                  0 |             0 |\n",
      "| 21 |   2001 |                  0 |             0 |\n",
      "| 22 |   2002 |                  0 |             0 |\n",
      "| 23 |   2003 |                  0 |             0 |\n",
      "| 24 |   2004 |                  0 |             0 |\n",
      "| 25 |   2005 |                  0 |             0 |\n",
      "| 26 |   2006 |                  0 |             0 |\n",
      "| 27 |   2007 |                  0 |             0 |\n",
      "| 28 |   2008 |                  0 |             0 |\n",
      "| 29 |   2009 |                  0 |             0 |\n",
      "| 30 |   2010 |                  0 |             0 |\n",
      "| 31 |   2011 |                  0 |             0 |\n",
      "| 32 |   2012 |                  0 |             0 |\n",
      "| 33 |   2013 |                  0 |             0 |\n",
      "| 34 |   2014 |                  0 |             0 |\n",
      "| 35 |   2015 |                  0 |             0 |\n",
      "| 36 |   2016 |                  0 |             0 |\n",
      "| 37 |   2017 |                  0 |             0 |\n",
      "| 38 |   2018 |                  0 |             0 |\n",
      "| 39 |   2019 |                  0 |             0 |\n",
      "1980-01-01T00:00:00Z\n",
      "1981-01-01T00:00:00Z\n",
      "1982-01-01T00:00:00Z\n",
      "1983-01-01T00:00:00Z\n",
      "1984-01-01T00:00:00Z\n",
      "1985-01-01T00:00:00Z\n",
      "1986-01-01T00:00:00Z\n",
      "1987-01-01T00:00:00Z\n",
      "1988-01-01T00:00:00Z\n",
      "1989-01-01T00:00:00Z\n",
      "1990-01-01T00:00:00Z\n",
      "1991-01-01T00:00:00Z\n",
      "1992-01-01T00:00:00Z\n",
      "1993-01-01T00:00:00Z\n",
      "1994-01-01T00:00:00Z\n",
      "1995-01-01T00:00:00Z\n",
      "1996-01-01T00:00:00Z\n",
      "1997-01-01T00:00:00Z\n",
      "1998-01-01T00:00:00Z\n",
      "1999-01-01T00:00:00Z\n",
      "2000-01-01T00:00:00Z\n",
      "2001-01-01T00:00:00Z\n",
      "2002-01-01T00:00:00Z\n",
      "2003-01-01T00:00:00Z\n",
      "2004-01-01T00:00:00Z\n",
      "2005-01-01T00:00:00Z\n",
      "2006-01-01T00:00:00Z\n",
      "2007-01-01T00:00:00Z\n",
      "2008-01-01T00:00:00Z\n",
      "2009-01-01T00:00:00Z\n",
      "2010-01-01T00:00:00Z\n",
      "2011-01-01T00:00:00Z\n",
      "2012-01-01T00:00:00Z\n",
      "2013-01-01T00:00:00Z\n",
      "2014-01-01T00:00:00Z\n",
      "2015-01-01T00:00:00Z\n",
      "2016-01-01T00:00:00Z\n",
      "2017-01-01T00:00:00Z\n",
      "2018-01-01T00:00:00Z\n",
      "2019-01-01T00:00:00Z\n",
      "[9.08, 9.15, 9.68, 9.76, 9.15, 8.21, 8.63, 8.42, 9.97, 10.36, 10.53, 9.35, 10.21, 9.37, 10.29, 10.1, 8.22, 9.89, 10.05, 10.63, 10.6, 10.03, 10.4, 10.12, 10.14, 10.36, 10.72, 10.92, 10.3, 10.17, 8.65, 10.49, 9.93, 9.37, 11.32, 10.44, 10.42, 10.66, 11.03, 11.11]\n",
      "|    |   Year |   amount_heatwaves |   avg_hw_temp |   avg_temp |\n",
      "|---:|-------:|-------------------:|--------------:|-----------:|\n",
      "|  0 |   1980 |                  0 |             0 |       9.08 |\n",
      "|  1 |   1981 |                  0 |             0 |       9.15 |\n",
      "|  2 |   1982 |                  0 |             0 |       9.68 |\n",
      "|  3 |   1983 |                  0 |             0 |       9.76 |\n",
      "|  4 |   1984 |                  0 |             0 |       9.15 |\n",
      "|  5 |   1985 |                  0 |             0 |       8.21 |\n",
      "|  6 |   1986 |                  0 |             0 |       8.63 |\n",
      "|  7 |   1987 |                  0 |             0 |       8.42 |\n",
      "|  8 |   1988 |                  0 |             0 |       9.97 |\n",
      "|  9 |   1989 |                  0 |             0 |      10.36 |\n",
      "| 10 |   1990 |                  0 |             0 |      10.53 |\n",
      "| 11 |   1991 |                  0 |             0 |       9.35 |\n",
      "| 12 |   1992 |                  0 |             0 |      10.21 |\n",
      "| 13 |   1993 |                  0 |             0 |       9.37 |\n",
      "| 14 |   1994 |                  0 |             0 |      10.29 |\n",
      "| 15 |   1995 |                  0 |             0 |      10.1  |\n",
      "| 16 |   1996 |                  0 |             0 |       8.22 |\n",
      "| 17 |   1997 |                  0 |             0 |       9.89 |\n",
      "| 18 |   1998 |                  0 |             0 |      10.05 |\n",
      "| 19 |   1999 |                  0 |             0 |      10.63 |\n",
      "| 20 |   2000 |                  0 |             0 |      10.6  |\n",
      "| 21 |   2001 |                  0 |             0 |      10.03 |\n",
      "| 22 |   2002 |                  0 |             0 |      10.4  |\n",
      "| 23 |   2003 |                  0 |             0 |      10.12 |\n",
      "| 24 |   2004 |                  0 |             0 |      10.14 |\n",
      "| 25 |   2005 |                  0 |             0 |      10.36 |\n",
      "| 26 |   2006 |                  0 |             0 |      10.72 |\n",
      "| 27 |   2007 |                  0 |             0 |      10.92 |\n",
      "| 28 |   2008 |                  0 |             0 |      10.3  |\n",
      "| 29 |   2009 |                  0 |             0 |      10.17 |\n",
      "| 30 |   2010 |                  0 |             0 |       8.65 |\n",
      "| 31 |   2011 |                  0 |             0 |      10.49 |\n",
      "| 32 |   2012 |                  0 |             0 |       9.93 |\n",
      "| 33 |   2013 |                  0 |             0 |       9.37 |\n",
      "| 34 |   2014 |                  0 |             0 |      11.32 |\n",
      "| 35 |   2015 |                  0 |             0 |      10.44 |\n",
      "| 36 |   2016 |                  0 |             0 |      10.42 |\n",
      "| 37 |   2017 |                  0 |             0 |      10.66 |\n",
      "| 38 |   2018 |                  0 |             0 |      11.03 |\n",
      "| 39 |   2019 |                  0 |             0 |      11.11 |\n"
     ]
    }
   ],
   "source": [
    "country = 'Netherlands'\n",
    "product = 'Agriculture'\n",
    "\n",
    "def get_input_time_series(country):\n",
    "    \"\"\"\n",
    "    Returns the 3 time series of a certain country. Save as pickle file to later use with other data.\n",
    "    -----------------------------------------------------------------\n",
    "    Time Series 1: Amount heatwaves (per year)\n",
    "    Time Series 2: Average temperature during all heatwaves (per year)\n",
    "    Time Series 3: Average temperature in general\n",
    "    \"\"\"\n",
    "\n",
    "    # Read in the full dataset, and only keep the heatwave data of the given country.\n",
    "    colslist = ['Year','Disaster Subtype','Country','Start Month','Start Day','End Month','End Day']\n",
    "    df = pd.read_excel('disaster_data.xlsx',usecols=colslist)\n",
    "    df = df[df['Disaster Subtype'] == 'Heat wave']\n",
    "    df = df[df['Country'] == country]\n",
    "    df = df[df['Year'] >= 1980] # we only have temperature data from 1980-2019!\n",
    "    df = df[df['Year'] <= 2019]\n",
    "    year_list = np.linspace(1980,2019,2020-1980)\n",
    "    df_out = pd.DataFrame({\"Year\": year_list})\n",
    "    df_merged = pd.merge(df_out, df, how='left', on='Year')\n",
    "\n",
    "    #-------------- Time Series 1: Amount heatwaves (per year) --------------#\n",
    "    amount_list = [len(df[df['Year'] == y].index) for y in year_list]\n",
    "    df_out['amount_heatwaves'] = amount_list\n",
    "    #plot(df_out, 'amount_heatwaves')\n",
    "\n",
    "    #-------------- Time Series 2: Average temperature during all heatwaves (per year) --------------#\n",
    "\n",
    "    # only begin- and end month and day given. So need to compute the exact duration of the heatwave which depends on the starting month.\n",
    "    # Further, sometimes there's no start or end day given. If that's the case, take the avg temp of the month given.\n",
    "\n",
    "    df = df.assign(month_difference=lambda row: row['End Month'] - row['Start Month'])\n",
    "    df = df.assign(day_difference=lambda row: row['End Day'] - row['Start Day'])\n",
    "    # TO DO: we only have temperature data from 1980 up until end of 2019 so we need to drop all our invalid heatwave data before computing temperatures\n",
    "    # df = df(df['Year'] >= 1980)\n",
    "    # df = df(df['Year'] <= 2015)\n",
    "    df['duration'] = np.where(df['day_difference'] >= 0, df['day_difference'], 0)\n",
    "    df['duration'] = np.where(df['day_difference'].isna(),get_month_to_day(df['Start Month']),df['duration']) # this can be still adjusted!\n",
    "    df['duration'] = np.where(df['month_difference'] == 1, get_month_to_day(df['Start Month'])-df['Start Day'] + df['End Day'], df['duration'])\n",
    "    df['duration'] = np.where(df['duration'].isna(), 30, df['duration']) # this can be still adjusted!\n",
    "    df['start_day_for_duration'] = np.where(~df['Start Day'].isna(),df['Start Day'],1) # this can be still adjusted!\n",
    "\n",
    "    # convert pd data to lists so we can perform the get_avg_temp function\n",
    "    day_mapping = {1.0 :'01', 2.0 : '02', 3.0 : '03', 4.0 : '04', 5.0 : '05', 6.0 : '06', 7.0 : '07', 8.0 : '08', 9.0 : '09', 10.0 : '10', 11.0 : '11', 12.0 : '12', 13.0 : '13', 14.0 : '14', 15.0 : '15', 16.0 : '16', 17.0 : '17', 18.0 : '18', 19.0 : '19', 20.0 : '20', 21.0 : '21', 22.0 : '22', 23.0 : '23', 24.0 : '24', 25.0 : '25', 26.0 : '26', 27.0 : '27', 28.0 : '28', 29.0 : '29', 30.0 : '30', 31.0 : '31'}\n",
    "    years_heatwave_list = [y for y in df['Year']]\n",
    "    begin_month_list = [day_mapping[m] for m in df['Start Month']]\n",
    "    begin_day_list = [day_mapping[day] for day in df['start_day_for_duration']]\n",
    "    duration_list = [round(dur) for dur in df['duration']]\n",
    "    avg_temps = [get_avg_temp(years_heatwave_list[i], begin_month_list[i], begin_day_list[i], duration_list[i], country) for i in range(len(years_heatwave_list))]\n",
    "\n",
    "    # Compute avg temp --> list can be: [2003, 2006, 2015, 2018, 2019, 2019, 2019], take avg of the 2019 temps\n",
    "    years_heatwave_array = np.array(years_heatwave_list)\n",
    "    years_heatwave_array_unique = np.unique(years_heatwave_array)\n",
    "    indices_array = [np.where(years_heatwave_array == year)[0] for year in years_heatwave_array_unique]\n",
    "    df_out['avg_hw_temp'] = 0 # When there's no heatwave in a year, we put the avg temp = 0 for the time series\n",
    "    for counter,indices in enumerate(indices_array):\n",
    "        print(counter)\n",
    "        temps = [avg_temps[ind] for ind in indices]\n",
    "        avg_temp = round(sum(temps)/len(temps),2)\n",
    "        print(avg_temp)\n",
    "        df_out['avg_hw_temp'] = np.where(df_out['Year'] == years_heatwave_array_unique[counter],avg_temp,df_out['avg_hw_temp'])\n",
    "    print(df_out.to_markdown())\n",
    "    #plot(df_out,'avg_hw_temp')\n",
    "\n",
    "    #-------------- Time Series 3: Average temperature in general --------------#\n",
    "    avg_temps = [get_avg_temp(int(y), '01', '01', 365, country) for y in year_list]\n",
    "    print(avg_temps)\n",
    "    df_out['avg_temp'] = avg_temps\n",
    "    print(df_out.to_markdown())\n",
    "    #plot(df_out,'avg_temp')\n",
    "    df_out.to_pickle(f\"{country}.pkl\")\n",
    "\n",
    "    return df_out\n",
    "\n",
    "df = get_input_time_series(country)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373ec2eb",
   "metadata": {},
   "source": [
    "## Merging HeatWave data with production index data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5a69157",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_production_index_time_series(country, item):\n",
    "    df = pd.read_excel('World_prodvolumes.xls')\n",
    "\n",
    "    all_countries = df['Area'].unique()\n",
    "    all_items = df['Item'].unique()\n",
    "\n",
    "    df = df[df['Area'] == country]\n",
    "    df = df[df['Item'] == item]\n",
    "    df = df[df['Year'] >= 1980]  # we only have temperature data from 1980-2019!\n",
    "    df = df[df['Year'] <= 2019]\n",
    "    df = df[['Year','Value']]\n",
    "    df.fillna(df.mean(), inplace=True)\n",
    "\n",
    "    print(all_countries)\n",
    "    print(all_items)\n",
    "    print(df.to_markdown())\n",
    "\n",
    "    return df\n",
    "\n",
    "    #get_production_index_time_series('Afghanistan','Agriculture')\n",
    "\n",
    "def merge_time_series(country, item):\n",
    "    \"\"\"\n",
    "    Read out a already computed pkl file of the 3 heat-related input time series and concatenate the product index time series to it.\n",
    "    \"\"\"\n",
    "    df = pd.read_pickle(f\"{country}.pkl\")\n",
    "    df_item = get_production_index_time_series(country, item)\n",
    "    df_item = df_item.set_index(df.index) # indices have to be adjusted, otherwise NaN values!\n",
    "    df['Value'] = df_item['Value']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc60d4f",
   "metadata": {},
   "source": [
    "## Importing DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd6eef5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Afghanistan' 'Albania' 'Algeria' 'Angola' 'Antigua and Barbuda'\n",
      " 'Argentina' 'Armenia' 'Australia' 'Austria' 'Azerbaijan' 'Bahamas'\n",
      " 'Bahrain' 'Bangladesh' 'Barbados' 'Belarus' 'Belgium'\n",
      " 'Belgium-Luxembourg' 'Belize' 'Benin' 'Bhutan'\n",
      " 'Bolivia (Plurinational State of)' 'Bosnia and Herzegovina' 'Botswana'\n",
      " 'Brazil' 'Brunei Darussalam' 'Bulgaria' 'Burkina Faso' 'Burundi'\n",
      " 'Cabo Verde' 'Cambodia' 'Cameroon' 'Canada' 'Central African Republic'\n",
      " 'Chad' 'Channel Islands' 'Chile' 'China, Hong Kong SAR'\n",
      " 'China, Macao SAR' 'China, mainland' 'China, Taiwan Province of'\n",
      " 'Colombia' 'Comoros' 'Congo' 'Cook Islands' 'Costa Rica' \"C?te d'Ivoire\"\n",
      " 'Croatia' 'Cuba' 'Cyprus' 'Czechia' 'Czechoslovakia'\n",
      " \"Democratic People's Republic of Korea\"\n",
      " 'Democratic Republic of the Congo' 'Denmark' 'Djibouti' 'Dominica'\n",
      " 'Dominican Republic' 'Ecuador' 'Egypt' 'El Salvador' 'Equatorial Guinea'\n",
      " 'Eritrea' 'Estonia' 'Eswatini' 'Ethiopia' 'Ethiopia PDR' 'Faroe Islands'\n",
      " 'Fiji' 'Finland' 'France' 'French Guyana' 'French Polynesia' 'Gabon'\n",
      " 'Gambia' 'Georgia' 'Germany' 'Ghana' 'Greece' 'Grenada' 'Guadeloupe'\n",
      " 'Guatemala' 'Guinea' 'Guinea-Bissau' 'Guyana' 'Haiti' 'Honduras'\n",
      " 'Hungary' 'Iceland' 'India' 'Indonesia' 'Iran (Islamic Republic of)'\n",
      " 'Iraq' 'Ireland' 'Israel' 'Italy' 'Jamaica' 'Japan' 'Jordan' 'Kazakhstan'\n",
      " 'Kenya' 'Kiribati' 'Kuwait' 'Kyrgyzstan'\n",
      " \"Lao People's Democratic Republic\" 'Latvia' 'Lebanon' 'Lesotho' 'Liberia'\n",
      " 'Libya' 'Lithuania' 'Luxembourg' 'Madagascar' 'Malawi' 'Malaysia'\n",
      " 'Maldives' 'Mali' 'Malta' 'Marshall Islands' 'Martinique' 'Mauritania'\n",
      " 'Mauritius' 'Mexico' 'Micronesia (Federated States of)' 'Monaco'\n",
      " 'Mongolia' 'Montenegro' 'Morocco' 'Mozambique' 'Myanmar' 'Namibia'\n",
      " 'Nauru' 'Nepal' 'Netherlands' 'New Caledonia' 'New Zealand' 'Nicaragua'\n",
      " 'Niger' 'Nigeria' 'Niue' 'North Macedonia' 'Norway' 'Oman' 'Pakistan'\n",
      " 'Palestine' 'Panama' 'Papua New Guinea' 'Paraguay' 'Peru' 'Philippines'\n",
      " 'Poland' 'Portugal' 'Puerto Rico' 'Qatar' 'Republic of Korea'\n",
      " 'Republic of Moldova' 'R?union' 'Romania' 'Russian Federation' 'Rwanda'\n",
      " 'Saint Kitts and Nevis' 'Saint Lucia' 'Saint Vincent and the Grenadines'\n",
      " 'Samoa' 'Sao Tome and Principe' 'Saudi Arabia' 'Senegal' 'Serbia'\n",
      " 'Serbia and Montenegro' 'Seychelles' 'Sierra Leone' 'Singapore'\n",
      " 'Slovakia' 'Slovenia' 'Solomon Islands' 'Somalia' 'South Africa'\n",
      " 'South Sudan' 'Spain' 'Sri Lanka' 'Sudan' 'Sudan (former)' 'Suriname'\n",
      " 'Svalbard and Jan Mayen Islands' 'Sweden' 'Switzerland'\n",
      " 'Syrian Arab Republic' 'Tajikistan' 'Thailand' 'Timor-Leste' 'Togo'\n",
      " 'Tokelau' 'Tonga' 'Trinidad and Tobago' 'Tunisia' 'Turkey' 'Turkmenistan'\n",
      " 'Tuvalu' 'Uganda' 'Ukraine' 'United Arab Emirates'\n",
      " 'United Kingdom of Great Britain and Northern Ireland'\n",
      " 'United Republic of Tanzania' 'United States of America' 'Uruguay' 'USSR'\n",
      " 'Uzbekistan' 'Vanuatu' 'Venezuela (Bolivarian Republic of)' 'Viet Nam'\n",
      " 'Yemen' 'Yugoslav SFR' 'Zambia' 'Zimbabwe']\n",
      "['Agriculture' 'Cereals, Total' 'Food' 'Livestock' 'Milk, Total'\n",
      " 'Vegetables and Fruit Primary']\n",
      "|       |   Year |   Value |\n",
      "|------:|-------:|--------:|\n",
      "| 31680 |   1980 |   96.21 |\n",
      "| 31681 |   1981 |   99.19 |\n",
      "| 31682 |   1982 |  101.91 |\n",
      "| 31683 |   1983 |  101.33 |\n",
      "| 31684 |   1984 |  106.02 |\n",
      "| 31685 |   1985 |  106.27 |\n",
      "| 31686 |   1986 |  108.54 |\n",
      "| 31687 |   1987 |  107.08 |\n",
      "| 31688 |   1988 |  105.64 |\n",
      "| 31689 |   1989 |  102.83 |\n",
      "| 31690 |   1990 |  106.53 |\n",
      "| 31691 |   1991 |  100.69 |\n",
      "| 31692 |   1992 |  105.79 |\n",
      "| 31693 |   1993 |  105.12 |\n",
      "| 31694 |   1994 |  100.93 |\n",
      "| 31695 |   1995 |  101.56 |\n",
      "| 31696 |   1996 |  102.69 |\n",
      "| 31697 |   1997 |   96.9  |\n",
      "| 31698 |   1998 |   97.73 |\n",
      "| 31699 |   1999 |  102.37 |\n",
      "| 31700 |   2000 |  100.78 |\n",
      "| 31701 |   2001 |   93.22 |\n",
      "| 31702 |   2002 |   92.47 |\n",
      "| 31703 |   2003 |   86.05 |\n",
      "| 31704 |   2004 |   90.98 |\n",
      "| 31705 |   2005 |   88.87 |\n",
      "| 31706 |   2006 |   86.49 |\n",
      "| 31707 |   2007 |   88.79 |\n",
      "| 31708 |   2008 |   89.94 |\n",
      "| 31709 |   2009 |   92.14 |\n",
      "| 31710 |   2010 |   91.6  |\n",
      "| 31711 |   2011 |   94.83 |\n",
      "| 31712 |   2012 |   92.22 |\n",
      "| 31713 |   2013 |   94.53 |\n",
      "| 31714 |   2014 |   97.49 |\n",
      "| 31715 |   2015 |   99.84 |\n",
      "| 31716 |   2016 |  102.67 |\n",
      "| 31717 |   2017 |  102.58 |\n",
      "| 31718 |   2018 |   95.97 |\n",
      "| 31719 |   2019 |   99.01 |\n"
     ]
    }
   ],
   "source": [
    "df_total = merge_time_series(country,product)\n",
    "df_total = df_total.drop('Year',axis=1) # not needed. Maybe later for plotting.\n",
    "amount = len(df_total)\n",
    "df_train = df_total[:math.floor(amount -5)]\n",
    "df_test = df_total[math.floor(amount -5):]\n",
    "y_true = np.array(df_test[\"Value\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629abfdc",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e9f2cf",
   "metadata": {},
   "source": [
    "### Scaling the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8788a6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale training and test sets\n",
    "sc1 = MinMaxScaler(feature_range=(0,1))\n",
    "scaled_df_train = sc1.fit_transform(df_train)\n",
    "scaled_df_test = sc1.fit_transform(df_test)\n",
    "\n",
    "\n",
    "# now we have a numpy array and we tranform back to a dataframe with the scaled values\n",
    "scaled_df_train1 = pd.DataFrame(scaled_df_train, columns = ['amount_heatwaves','avg_hw_temp','avg_temp', 'Value'])\n",
    "scaled_df_test1 = pd.DataFrame(scaled_df_test, columns = ['amount_heatwaves','avg_hw_temp','avg_temp', 'Value'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd98b51",
   "metadata": {},
   "source": [
    "### Create X_train and y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6b7843a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = scaled_df_train1.drop(\"Value\", axis = 1) \n",
    "y_train = scaled_df_train1[\"Value\"]\n",
    "\n",
    "X_test = scaled_df_test1.drop(\"Value\", axis = 1)\n",
    "y_test = scaled_df_test1[\"Value\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea7ad59",
   "metadata": {},
   "source": [
    " ## MODEL 1 : Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "750e91c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error from linear regression:  0.0738870047987177\n",
      "Mean absolute error from linear regression:  0.2560676897027294\n"
     ]
    }
   ],
   "source": [
    "lr_model = linear_model.LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "y_pred_lr = lr_model.predict(X_test)\n",
    "mse_lr = mean_squared_error(y_test, y_pred_lr)\n",
    "mae_lr = mean_absolute_error(y_test, y_pred_lr)\n",
    "print('Mean squared error from linear regression: ', mse_lr)\n",
    "print('Mean absolute error from linear regression: ', mae_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63a4a47",
   "metadata": {},
   "source": [
    "## Model 2 : Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2cf7768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error using decision tree:  0.03340323366369951\n",
      "Mean absolute error using decision tree:  0.15511769741775758\n"
     ]
    }
   ],
   "source": [
    "### Decision tree\n",
    "tree = DecisionTreeRegressor()\n",
    "tree.fit(X_train, y_train)\n",
    "y_pred_tree = tree.predict(X_test)\n",
    "mse_dt = mean_squared_error(y_test, y_pred_tree)\n",
    "mae_dt = mean_absolute_error(y_test, y_pred_tree)\n",
    "print('Mean squared error using decision tree: ', mse_dt)\n",
    "print('Mean absolute error using decision tree: ', mae_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007ba042",
   "metadata": {},
   "source": [
    "## Model 3 : Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63647c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error using Random Forest:  0.041281331688611304\n",
      "Mean absolute error Using Random Forest:  0.18290870812677393\n",
      "avg_temp            1.0\n",
      "amount_heatwaves    0.0\n",
      "avg_hw_temp         0.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Random forest.\n",
    "#Increase number of trees and see the effect\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "model = RandomForestRegressor(n_estimators = 50, random_state=30)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_RF = model.predict(X_test)\n",
    "\n",
    "mse_RF = mean_squared_error(y_test, y_pred_RF)\n",
    "mae_RF = mean_absolute_error(y_test, y_pred_RF)\n",
    "print('Mean squared error using Random Forest: ', mse_RF)\n",
    "print('Mean absolute error Using Random Forest: ', mae_RF)\n",
    "\n",
    "#Feature ranking...\n",
    "feature_list = list(X_train.columns)\n",
    "feature_imp = pd.Series(model.feature_importances_, index=feature_list).sort_values(ascending=False)\n",
    "print(feature_imp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb52eeb9",
   "metadata": {},
   "source": [
    "## Model 4 : MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d853b985",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-25 16:38:48.035424: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    }
   ],
   "source": [
    "### Modelling\n",
    "\n",
    "# Set random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Create a model using the Sequential API\n",
    "model = tf.keras.Sequential([\n",
    "  tf.keras.layers.Dense(128), # 128 units\n",
    "  tf.keras.layers.Dense(64), # 64 units\n",
    "  tf.keras.layers.Dense(1) # 1 unit (important for output layer)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss=tf.keras.losses.mae, # mae is short for mean absolute error\n",
    "              optimizer=tf.keras.optimizers.Adam(), \n",
    "              metrics=[\"mae\"])\n",
    "\n",
    "# Fit the model\n",
    "# model.fit(X, y, epochs=5) # this will break with TensorFlow 2.7.0+\n",
    "history = model.fit(X_train, y_train, epochs=100, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c90f965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2447 - mae: 0.2447\n",
      "Mean squared error from neural net:  0.2446630299091339\n",
      "Mean absolute error from neural net:  0.2446630299091339\n"
     ]
    }
   ],
   "source": [
    "# Check the results of our model\n",
    "\n",
    "mse_neural, mae_neural = model.evaluate(X_test, y_test)\n",
    "print('Mean squared error from neural net: ', mse_neural)\n",
    "print('Mean absolute error from neural net: ', mae_neural)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "41fbf6f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAAAqDUlEQVR4nO3deZxU1Zn/8c9TVd1dvdFsDQrNqiBgK4uAIIpGE9cYzcQkaNSoMcZJzCQzGY1mmcwkM0lmnCzzMy5xEqNmUYxLJJGIUROXBGQHWWSRtVm7G+iGXmt5fn9UwbRtAw10dUHf7/v14mXfW/feeg5gfTnn1j3H3B0REQmuULYLEBGR7FIQiIgEnIJARCTgFAQiIgGnIBARCbhItgs4Ur179/bBgwdnuwwRkRPKggULqty9tK3XTrggGDx4MPPnz892GSIiJxQz23iw1zQ0JCIScAoCEZGAUxCIiATcCXePQETkaMViMSoqKmhsbMx2KRkTjUYpKysjJyen3ecoCEQkMCoqKiguLmbw4MGYWbbL6XDuTnV1NRUVFQwZMqTd52V0aMjMLjWzVWa21szubuP1EjP7vZktMbPlZnZzJusRkWBrbGykV69eXTIEAMyMXr16HXGPJ2NBYGZh4H7gMmAUcK2ZjWp12BeAFe4+GrgA+IGZ5WaqJhGRrhoC+x1N+zLZI5gIrHX3de7eDDwJXNXqGAeKLVV5EbALiGeimPUr5jH7f7/Mrp1bMnF5EZETViaDoD+wucV2RXpfSz8BRgJbgbeBL7l7svWFzOw2M5tvZvMrKyuPqpjdm5Yzecsv2LOz4qjOFxHpCEVFRdku4X0yGQRt9U9ar4JzCbAY6AeMAX5iZt3ed5L7w+4+3t3Hl5a2+YT0YUXyUr/5zfW1R3W+iEhXlckgqAAGtNguI/Uv/5ZuBp71lLXAemBEJoqJ5KeCINa4LxOXFxE5Iu7OnXfeSXl5OWeccQbTp08HYNu2bUydOpUxY8ZQXl7OG2+8QSKR4Kabbjpw7I9+9KMOrSWTXx+dBwwzsyHAFmAacF2rYzYBFwFvmFlf4DRgXSaKyU0HQbyxLhOXF5ETzL/9fjkrtnbsCMGoft341pWnt+vYZ599lsWLF7NkyRKqqqqYMGECU6dO5Te/+Q2XXHIJX//610kkEtTX17N48WK2bNnCsmXLANizZ0+H1p2xIHD3uJndAcwCwsAj7r7czG5Pv/4Q8B3gUTN7m9RQ0lfdvSoT9ewPgoR6BCJyHHjzzTe59tprCYfD9O3bl/PPP5958+YxYcIEbrnlFmKxGFdffTVjxoxh6NChrFu3ji9+8YtcccUVXHzxxR1aS0YfKHP3mcDMVvseavHzVqBjW3QQeQXFACSa1CMQEdr9L/dMcW99yzRl6tSpvP7667zwwgvccMMN3Hnnndx4440sWbKEWbNmcf/99/PUU0/xyCOPdFgtgZlrKFqQugftzQoCEcm+qVOnMn36dBKJBJWVlbz++utMnDiRjRs30qdPHz772c/ymc98hoULF1JVVUUymeRjH/sY3/nOd1i4cGGH1hKYKSbyC1M9AgWBiBwPPvrRjzJ79mxGjx6NmfFf//VfnHTSSTz22GPce++95OTkUFRUxOOPP86WLVu4+eabSSZT367/3ve+16G12MG6J8er8ePH+9EuTNP8rZ4s6P8pJt92XwdXJSIngpUrVzJy5Mhsl5FxbbXTzBa4+/i2jg/M0BBAo0UJxeqzXYaIyHElWEFAHqYgEBF5j0AFQZNFCccVBCIiLQUrCEL5RBIN2S5DROS4EqggiIWiCgIRkVaCFQThfHKSXXeJOhGRoxGoIIiH88lNqkcgItJSoIIgEcknTz0CEZH3CFQQJCMFRGnKdhkiEmAbNmxgxIgR3HrrrZSXl/OpT32Kl19+mSlTpjBs2DDmzp3L3LlzOeeccxg7diznnHMOq1atAiCRSHDnnXcyYcIEzjzzTH760592SE2BmWICwHMKibp6BCIC/PFu2P52x17zpDPgsu8f9rC1a9fy29/+locffpgJEybwm9/8hjfffJMZM2bw3e9+l8cff5zXX3+dSCTCyy+/zNe+9jWeeeYZfv7zn1NSUsK8efNoampiypQpXHzxxQwZMuSYyg5YEBSQb80kEwlC4XC2yxGRgBoyZAhnnHEGAKeffjoXXXQRZsYZZ5zBhg0bqKmp4dOf/jRr1qzBzIjFYgC89NJLLF26lKeffhqAmpoa1qxZoyA4EpZbAEBD/V4Ki7tntxgRya52/Ms9U/Ly8g78HAqFDmyHQiHi8Tjf/OY3+cAHPsBzzz3Hhg0buOCCC4DU1NX33Xcfl1xySYfWE6h7BJZbCEBD3d4sVyIicnA1NTX0798fgEcfffTA/ksuuYQHH3zwQA9h9erV1NUd+4zKgQqCUF4qCJq0gL2IHMfuuusu7rnnHqZMmUIikTiw/9Zbb2XUqFGMGzeO8vJyPve5zxGPx4/5/QI1DfXCP/6CcW99mXXXvMTQ8rM7uDIROd5pGmpNQ004mlq3uLlBQ0MiIvsFKghy0kEQa9AqZSIi+wUrCPJTQRBvVI9AJKhOtOHwI3U07QtUEOTmp9YtTjSpRyASRNFolOrq6i4bBu5OdXU10Wj0iM4L1HME0fQC9kkFgUgglZWVUVFRQWVlZbZLyZhoNEpZWdkRnROsICjoBkCyWUEgEkQ5OTnH/BRuVxSooaH8dI/AFQQiIgdkNAjM7FIzW2Vma83s7jZev9PMFqd/LTOzhJn1zFQ9uXlRYh6GZq1bLCKyX8aCwMzCwP3AZcAo4FozG9XyGHe/193HuPsY4B7gNXfflamaABosj1BMPQIRkf0y2SOYCKx193Xu3gw8CVx1iOOvBZ7IYD0ANBLFYuoRiIjsl8kg6A9sbrFdkd73PmZWAFwKPJPBegBosihhLWAvInJAJoPA2th3sC/vXgn89WDDQmZ2m5nNN7P5x/q1r+ZQlHBcQSAisl8mg6ACGNBiuwzYepBjp3GIYSF3f9jdx7v7+NLS0mMqqjkUJUc9AhGRAzIZBPOAYWY2xMxySX3Yz2h9kJmVAOcDz2ewlgNi4XxykgoCEZH9MvZAmbvHzewOYBYQBh5x9+Vmdnv69YfSh34UeMndO+WrPIlwPrnNXfepQhGRI5XRJ4vdfSYws9W+h1ptPwo8msk6WopHCsjVAvYiIgcE6sligGSkgKiCQETkgMAFgUfyiXpTtssQETluBC8IcgspsCaSLdYBFREJssAFgeUUANBQr8VpREQgiEGQVwhAQ52CQEQEghgEuakgaKrfl+VKRESOD4ELgnBeat3i5obaLFciInJ8CFwQRKLpHkGDegQiIhDIIEj1COIKAhERIIBBkFuQWq4y3qjFaUREIIhBkJ8Ogib1CEREIIBBkFeQGhpKNqlHICICAQyC/PTQkIJARCQlcEEQLUwFgTdraEhEBAIYBLm5UeIegmYtYC8iAgEMAguFaCAPiykIREQggEEA0GhRQnEFgYgIBDQImixKOK51i0VEIKhBEIoSTigIREQgoEEQC+UTURCIiAABDYLmcD45CgIRESCgQZAI55Ob1AL2IiIQ4CDIcwWBiAgENQhyCoi6hoZERCCgQeCRAqLelO0yRESOC4EMAnIKKLAmkolEtisREcm6jAaBmV1qZqvMbK2Z3X2QYy4ws8VmttzMXstkPft5egH7Rq1SJiJCJFMXNrMwcD/wIaACmGdmM9x9RYtjugMPAJe6+yYz65OpeloK5RYA0FC3l4Kiks54SxGR41YmewQTgbXuvs7dm4EngataHXMd8Ky7bwJw950ZrOcAy0svYF+vHoGISCaDoD+wucV2RXpfS8OBHmb2FzNbYGY3tnUhM7vNzOab2fzKyspjLiy8Pwga9h7ztURETnSZDAJrY5+32o4AZwFXAJcA3zSz4e87yf1hdx/v7uNLS0uPubBINLU4TXO9gkBEJGP3CEj1AAa02C4DtrZxTJW71wF1ZvY6MBpYncG6iERT6xbH1CMQEcloj2AeMMzMhphZLjANmNHqmOeB88wsYmYFwNnAygzWBEBeYTdAQSAiAhnsEbh73MzuAGYBYeARd19uZrenX3/I3Vea2YvAUiAJ/Mzdl2Wqpv3y0gvYJxoVBCIimRwawt1nAjNb7Xuo1fa9wL2ZrKO1/MLuACQa9a0hEZFAPlkcLUoNDXmTegQiIoEMgoL0PQJvrstyJSIi2RfIIAiFw9R7HtasoSERkUAGAUC95ROKqUcgIhLYIGiwAsIKAhGR4AZBUyifcLw+22WIiGRdYIOgOVxATkI9AhGRwAZBLJxPXkI9AhGRwAZBPFJIXlLrFouIBDYIEhEtYC8iAgEOgmROEfnemO0yRESyLrBB4LmFFNCIJ5PZLkVEJKsCGwSWW0TInAYtTiMiARfcIMhLLU5Tv68my5WIiGRXYIMglF6usnFfbZYrERHJrsAGQSQ/NQNpY516BCISbMENgv0L2Gu5ShEJuMAGQW56ucpYvYaGRCTY2hUEZvYlM+tmKT83s4VmdnGmi8uk/QvYx7VusYgEXHt7BLe4ey1wMVAK3Ax8P2NVdYJoYQkACQ0NiUjAtTcILP3fy4FfuPuSFvtOSPnpHkGySauUiUiwtTcIFpjZS6SCYJaZFQMn9CO5+UWpHoEWsBeRoIu087jPAGOAde5eb2Y9SQ0PnbBy86I0ewS0brGIBFx7ewSTgVXuvsfMrge+AZzwX8Cvs3xCMa1JICLB1t4geBCoN7PRwF3ARuDxjFXVSRqJEoqpRyAiwdbeIIi7uwNXAf/j7v8DFB/uJDO71MxWmdlaM7u7jdcvMLMaM1uc/vUvR1b+sWkMFRDRusUiEnDtvUew18zuAW4AzjOzMJBzqBPSx9wPfAioAOaZ2Qx3X9Hq0Dfc/cNHWHeHaA7lE4lr3WIRCbb29gg+CTSRep5gO9AfuPcw50wE1rr7OndvBp4k1aM4bjSHC8hNaJUyEQm2dgVB+sP/10CJmX0YaHT3w90j6A9sbrFdkd7X2mQzW2JmfzSz09u6kJndZmbzzWx+ZWVle0pul1ikkLykhoZEJNjaO8XEJ4C5wMeBTwBvmdk1hzutjX3eanshMMjdRwP3Ab9r60Lu/rC7j3f38aWlpe0puV0SkQItYC8igdfeewRfBya4+04AMysFXgaePsQ5FcCAFttlwNaWB6Snrdj/80wze8DMert7VTvrOibJnELyURCISLC19x5BaH8IpFW349x5wDAzG2JmucA0YEbLA8zsJDOz9M8T09esbmdNxyyZU0SBFrAXkYBrb4/gRTObBTyR3v4kMPNQJ7h73MzuAGYBYeARd19uZrenX38IuAb4ezOLAw3AtPTXVDtHXiG5Fqe5qZHcvGinva2IyPGkXUHg7nea2ceAKaTG/h929+facd5MWgVGOgD2//wT4CdHVHEHstzUusUN+2oUBCISWO3tEeDuzwDPZLCWThdOr1JWv28PJb36ZrkaEZHsOGQQmNle3v9NH0j1Ctzdu2Wkqk4SiqZ6BE31moFURILrkEHg7oedRuJEpgXsRUQCvGYxQE6+1i0WEQl0EOQVpHoEsQbNQCoiwaUgABIN6hGISHAFOgii6eUqtW6xiARZoIOgsLg7oCAQkWALdBBE8wtJuGndYhEJtEAHgYVC1BPFFAQiEmCBDgKABssnFNMqZSISXIEPgsZQPmEFgYgEWOCDoMnyiSS0SpmIBFfgg6A5XEBOXEEgIsEV+CCIhQvI1XKVIhJggQ+CeKSQqBawF5EAC3wQJHMKiLp6BCISXAqCnCIKFAQiEmCBDwLPLaTAmkgmEtkuRUQkKwIfBJaXWqWsvk4zkIpIMCkI8lKL0zTs0yplIhJMgQ+CcLpHoOUqRSSoAh8E/7dusYaGRCSYFAT5qR5Bc/3eLFciIpIdgQ+C3ILUKmUxLVcpIgEV+CAo7N4HgObanVmuREQkOzIaBGZ2qZmtMrO1Znb3IY6bYGYJM7smk/W0pdfJAwFI7NnS2W8tInJcyFgQmFkYuB+4DBgFXGtmow5y3H8CszJVy6FE8wvZTTGhfduz8fYiIlmXyR7BRGCtu69z92bgSeCqNo77IvAMkLWxmd2hXuQ17MjW24uIZFUmg6A/sLnFdkV63wFm1h/4KPDQoS5kZreZ2Xwzm19ZWdnhhe7NLaWoSfcIRCSYMhkE1sY+b7X9Y+Cr7n7IiX7c/WF3H+/u40tLSzuqvgOa8vvQPVHd4dcVETkRRDJ47QpgQIvtMmBrq2PGA0+aGUBv4HIzi7v77zJY1/skik6m564aYs1N5OTmdeZbi4hkXSZ7BPOAYWY2xMxygWnAjJYHuPsQdx/s7oOBp4HPd3YIAIS69SNkTvWOzYc/WESki8lYELh7HLiD1LeBVgJPuftyM7vdzG7P1PsejWiv1K2LPTs2ZrkSEZHOl8mhIdx9JjCz1b42bwy7+02ZrOVQinqnniWor1KPQESCJ/BPFgP0OGkQAM279VCZiASPggDo0ftkmj2C17a+ly0i0vUpCAALhagK9SSnTk8Xi0jwKAjSaiK9yW/UQ2UiEjwKgrT6vD50i1VluwwRkU6nIEiLFfSlV7IaTyazXYqISKdSEOzX7WQKrInaml3ZrkREpFMpCNIi3VMPle3eviG7hYiIdDIFQVpBr9S0SHt3bspyJSIinUtBkFbSN/V0ccMuPVQmIsGiIEjrlX66OFGjIBCRYFEQpEULithDEaG927JdiohIp1IQtLA71JvcBj1UJiLBoiBoQUtWikgQKQhaaMzvQ4+Eni4WkWBRELSQLDyJnp5aslJEJCgUBC1YSfuWrGxsqKO5qbGTqhIRySwFQQt5PcuAgy9Z2dhQx+zHvkbi+0Op+96pzHnwc2x8Z2Fnligi0uEyulTliaaod+rp4raWrFzy6lOUvvENJvsOFhWeg4cinLX9t+Q8+SSrIqexe+iVDD3/evr0H9LZZYuIHBP1CFroO3gkjZ5DfNVL79m/dcMqRr12O82Wx7KLHmfsXX9k3D//ntrPL2XOKV8i4jEmrf5vej88lnk/nkYiHs9SC0REjpyCoIXikp4sKb2SMbteZOeW9Qf2b/79d3Eg/5bfUX7eVQf29+pbxqQbvs0p31zEputeY27fjzNhzx+Z99PbNZ21iJwwFAStDLjiq4Rw1s34TwAqt25gTNULLOp1BX3LTjnoeQOHj2HS5/+XOX2nManyt7z1xHc6q2QRkWOiIGil35ARLC65kDO2P0dN9Q7eff77hElQ9uGvtev8ibc9wMKiqUxa80MWvPCzDFcrInLsFARt6HnxXRRaIyunf4Mztz/L4pKL6D90ZLvODYXDjPrCk6zMOZ3yuXezeuFrGa5WROTYKAjaMLT8bJbkT2TSzqeI0kzpZfcc0fnR/EL6fva37LLudJ9xE5VbN2SmUBGRDpDRIDCzS81slZmtNbO723j9KjNbamaLzWy+mZ2byXqORM75XwFgcdF5DBp51hGf37NPfxqu+TVFXsfuRz5OY0NdR5coItIhMhYEZhYG7gcuA0YB15rZqFaHvQKMdvcxwC3AcTOoPnLixcwb8x/0v/bHR32NoeVns+qcexkeX82Kn3yS3ZWa4lpEjj+Z7BFMBNa6+zp3bwaeBK5qeYC773N3T28WAs5xwkIhJlx9xyG/KdQeYy/5NHNO+RKj971J5CdjmfPo12io29tBVYqIHLtMBkF/oOUjuhXpfe9hZh81s3eAF0j1Ct7HzG5LDx3Nr6yszEixmTTphm9TMe0V1haOZdKG+6m9dzRLXn0q22WJiACZDQJrY9/7/sXv7s+5+wjgaqDNL9+7+8PuPt7dx5eWlnZslZ1k0MizGHvXH1lx6XQaQoWMfv2zzPvRJ6ip3pHt0kQk4DIZBBXAgBbbZcDWgx3s7q8Dp5hZ7wzWlHWjJl3KyXe9xeyyWxi7508k7xvPnAdvZ92yt7JdmogElP3fEH0HX9gsAqwGLgK2APOA69x9eYtjTgXedXc3s3HA74EyP0RR48eP9/nz52ek5s62dslf2fvSdzl932xyLcGG0EB2FQyhqXgAoZIyQtFuRPKLCOXkEdu3m3jtDryuGks2Y4kY4OSNuJgzP/AJQuFwtpsjIscxM1vg7uPbei1js4+6e9zM7gBmAWHgEXdfbma3p19/CPgYcKOZxYAG4JOHCoGu5tTRU2D0C+yu3MaiVx4lf8PLlNatoe/ev5K7re2J65o9TDO5JCxExBMUVj3L5r9+m60jPs3oK+8gWlDUya0QkRNdxnoEmdKVegQHk0wk2FW5lab6Whrr9hJvqqegeyklvftR3K0HFkqN6MWam1jyp8fptuhhhsdXszoynN63/Y6efd53T15EAu5QPQIFQRfgySSLXnqcUbP/mapQb/jU05SdWp7tskTkOHKoINAUE12AhUKMu/QmNnz4SQp9H4W/uoxlb87IdlkicoJQEHQhIyZ8kH2feoE6K6T85RtYdO8VVKxdlu2yROQ4pyDoYgYMG03vO+cze/Dfc9q+efT55VRmP3IXyUQi26WJyHFKQdAFRQuKmHzT96n/+/ksLfkAkzf9lMU/vIr6fTVtHr990xremf8KOyreJR5r7uRqRSTbdLO4i/Nkkree+HcmrP4hGyKD2XvO3cQbaknU7YIdy+m/ey5lvv3A8Qk3KsJlbDv1k4y6/PN0694ri9WLSEfRt4aEpX9+miF/uYNiaziwb5/ns7ZwDI1l5xLtcwpNu7fiNVvovv1vjIivpN7zeLvPlYy47j8p6dGlH/gW6fIUBAJA1fZNVG5cSUFJKYXdS+nR+2TCkbafKVyz+A32/PknjNszi2rrwfbz7+XMD1zTyRWLSEdREMhRW73wNXL/8AUGJzczt8eHKf/MAxQUlWS7LBE5QnqOQI7a8HHnc9KdbzG7342M3/UCO394LptWL852WQAk4nFqdldluwyRE56CQA4rml/I5NvuY/lFv6AkuZuev76UhX/8RVZrWjX/VTZ8bzy5Px7Jopd+ldVaRE50GhqSI7J981pqHruO0+KrWFh4Hid9/Af0G3xap71/7Z5qVv7yn5hQ9TxV1oPacA+Gxtcxd8RdTLr2axl7392V21j1zHew5r1Y/3H0Gj6ZgaeNJSc3L2PvKdKRdI9AOlRzUyMLnvhXRq9/hBBJFg+4kTHXfTvjM596MsnSey+hvH4e8/p+gvLr/5NwOMI793+CsfV/Y07fa5l42/0dOiV3rLmJBU/fy6jVD1DgDdRblG7UAxD3ENtDfdiVV0ZTXi/cwmBGsnQkEz5xz0FvxItkg4JAMmJHxbtsnn4n4/e+wmbrR92l/8OIsy/O2PstfPFRxs35EnOG/zOTrvvmgf2JeJz5D93G2VXPsKD4Qsq/8GvyogXH/H61e6rZcd/FDEus5e28cRRffS8Dh49ly7pl7Fg5m9iOleTWbqSkfhOFiVoMJ0Kc3uxhaXQ8A2/9Nd17n3TMdcjBNdbvY8vapZQNH9Mhf+ZdmYJAMurt15+n96tfoa9XMa/Px+h17s0MHDGe3Lxoh73Hvtrd1P9wHHvD3Rl091tEcnLf87onk7z1q28xad3/Y1neGAZ9/jmKS3oe9fvFY82s+MFljGxYxNKzf8C4Sz99YPrvw5n79A8Z8/Z/UBXqSf3Vj6bWnegEjQ11vLvwL9SufJnuO+YQ9jg1hUOJ9xpOyfApjJjwoS6xgJEnk6ya/wq1cx5jZPXLFFsDDZ7Lu9FR7O03hWEf+hy9+w066us3NzWy5IWfEq/ZikVLiBT2oPS0yQw6bUzHNSILFASScXV797DssX/i7KpnAGjyHDbmDKG67zn0GHMlw8ZecExDJXMe/BwTt09n9ZXPMGL8RQc9bt7zDzBm4TfYEu7H9lOncfK4yxk4fEy7P8Qh9UEz9/6bObv6d8w949+Y+LEvH3G9qxf+hZIZt9DN97L6/PsYfeG0I77G4WrcvHYp2xa9SGjrInrtfYcBic3kWIKEG+/mDKM5XEDfpo2UshuArdaXjWUfYcD5Nx3RNOWeTB7R718mbVm3nN3TP09502LqPY/l3S+AoReQ2LKI0up5nJJYT7OHWdL9Q/T60D8xtPzsdl97/3Tufd76PmW+7X2vL8sbQ+ysz3LmhdNOyGE/BYF0mu2b1rBl2evENi2gpHoxw5pXErEku+nG6l4X0mPKLQwbc94RfbC8+/YcBj19GQt6fZiz/+GXhz3+7deepeS1bzAwuQWAnfRkZ95A6gsHkCgZSCi/B+FoMZGCEnr0H87JQ08nNy9KMpFg+6Y1bHz1Z0ze/L/MPvlGJn/uvqP+vajavpnd/3s1Q+LrWDT6X5nwd1866mvtt3X9O2z+w/cYVP0mJ5H66mwV3dkaHUZdz5HkD5nM0AmXvGdqkJpdlax582nylk/n9MbFhMxZHxrE9pMvpO/kaw/6YVmzu4p3fvUVzqyaSVWoN9X5g2joPpzSsz/Zab2c/Zoa61n41PcY++6DxIiwfMQXKb/i8xR16/Ge47asW07FzB9wRuUfKLAm5vSdxtibf3TIYaPdldtY/epj9Fr9FKcm3mVDaCA1536TUedexd49VezdXcnWOU8xZP10TqKK3XRjfdFYYgPPY8DEj3TqlyWOhYJAsqZmVyVrZz+PvzOT8trXiVqMDaGB7OgxjmTxyUS6l9F90JkMKZ/U5nDP/BkPcuri7+EY4S/Op6RX33a/99YNq9g87w+EN/+N4vrNlMa30ZPa9x0X8zA7Qn3okdxNoTUCsLBoKmP+8XfHPJRSt3cP797/d5zZuIDZ/W9m1DXfOKrpOrZvWsPG332bcdUvkCDEiqJJxAadT9n4y+k/9PT2X2fzWja88STFG2ZxWtMyIpZkYdH5lF71HQYMGw2khsUWz3qUwfP/gx5ew6KSDxJKNtGjfiP9ExXkWoK14VOoPm0aIz54MyU9S4+4PYdTtX0zW9+ZS926t+i2fQ6nNK0gajEWFZ5L/+t+Qp/+Qw55fk31Dt554h7OrnqGteFTyJv2iwPt2+/dt+dQ8+J/cMa+v5JjCdaHBlN5+s2M+8jn3/d3EVK/L0tfnU5ixe8ZVDOPPuwCYEXuGdSN+DinXXj9cT03l4JAjgu1e6pZ+adH6bb6GU6KbaZHiw/les9jfd4I9nY/Dbr1I9LtZPKWT+eMpoWsiowg+rEHGDTyrGOuoX5fDfW1e2io20N9TTV7t64itn0leTXrieWXQt/TKRk8muHjPtBh4+nNTY0seeBGJtTMoslzWF48meTwK7BIHh5vIpmIYZ7EPYkn4iQba6FhD+HGXRTWbaRv82Z6s4dmD7Oo9CqG/t23KO03+Jjr2lO1nZXP38voTb8klxgr8sfSrbmSfomt5FqcNZFh2JU/5tTR5x44p6Z6B+/86RF6r5meHoaJsKz4HOzMT1LcdzAWihAKh2nat4fGvdXE9lZj4QiR/G7k5HcjnJMLZpiFCIUjhCK5hCMRardvoG79XAoqF9G/YTW92QNA0o11kaFU9Z5AUfnllJ931RG1cfHLTzDozTvJ82ZWFk8mXjaJogFn0jjnZ5y191VqKWRF34/Q57ybj3gYqeLdt6n423TKNjzHAN8KQCU9qMwtoy6/H4loDzzaHcuJ4nW7iDRUEontJZbTjUR+b6ywJ+HivuSV9CW/ex9CoTDuTiLWRG3FShLbl5Nfs5aGbkMpPvNKhk/44DF9XVlBIMelxvp9VG5dz85VbxHfMJteuxbRL15BgTUBqUnxlo/6MhOuufOEv8npySRrFr/Brtm/ZHjlrDZ7Ji01e5haK6Yqpx+1hYNJ9jyVQedfz8mDOn4Yomr7Zt59+lv02TWfPdH+NJYMJbdsLGMuuemgY+GeTPLu23+j6q+PMXzni4dtT3sk3dgUHkBl8UgSfcopGjyWASMnHXOPY+eW9Wz87T0M3DOXvlQDqX94LCm77qh7aC15MsmqhX9mz7JXCO1ZT3HdRnrEdlDs+w70MJs9zG7rTkOogIJkHd29hlw79BohTZ7DtvBJ9EtsI9fi1FLAilM/x6Tr//Wo6lQQyAnDk0n21u5m17b1dC8t65Jfv4w1N1GxZjEWChPOySMcziEUDmOhEKFQmMJuPcgvKD5ubtAeTqy5idXzXyFWtwdPxkgm4uTklxAt6U1Bt94kk3Ea99XQXF9DMh4D91TvJ5nAE80k4zHyuvdlUPmUY/qm1+F4Msm2TWvYsWoOA0ZfSO+TBmTsvfZrbmqksaGO4m493vPnuf/veU3VVuqqt9FQsxN3x8ywcIQe/YfT/5RyIjm57KvdzerZfyC+cibh4R/krMs/c1S1KAhERAJOk86JiMhBKQhERAJOQSAiEnAZDQIzu9TMVpnZWjO7u43XP2VmS9O//mZmo9u6joiIZE7GgsDMwsD9wGXAKOBaMxvV6rD1wPnufibwHeDhTNUjIiJty2SPYCKw1t3XuXsz8CTwnqdB3P1v7r47vTkHKMtgPSIi0oZMBkF/YHOL7Yr0voP5DPDHDNYjIiJtyOQUetbGvjYfWjCzD5AKgnMP8vptwG0AAwcO7Kj6RESEzAZBBdDy0b0yYGvrg8zsTOBnwGXuXt3Whdz9YdL3D8ys0sw2HmVNvYEgrnYexHYHsc0QzHYHsc1w5O0+6CINGXuy2MwiwGrgImALMA+4zt2XtzhmIPAqcKO7/y0jhby3pvkHe7KuKwtiu4PYZghmu4PYZujYdmesR+DucTO7A5gFhIFH3H25md2efv0h4F+AXsADZgYQD+IfqIhINmV0mR13nwnMbLXvoRY/3wrcmskaRETk0IL2ZHFQn1MIYruD2GYIZruD2GbowHafcLOPiohIxwpaj0BERFpREIiIBFxgguBwE+B1BWY2wMz+bGYrzWy5mX0pvb+nmf3JzNak/9sj27V2NDMLm9kiM/tDejsIbe5uZk+b2TvpP/PJAWn3P6b/fi8zsyfMLNrV2m1mj5jZTjNb1mLfQdtoZvekP9tWmdklR/p+gQiCdk6A1xXEga+4+0hgEvCFdDvvBl5x92HAK+ntruZLwMoW20Fo8/8AL7r7CGA0qfZ36XabWX/gH4Dx7l5O6qvp0+h67X4UuLTVvjbbmP5/fBpwevqcB9Kfee0WiCCgHRPgdQXuvs3dF6Z/3kvqg6E/qbY+lj7sMeDqrBSYIWZWBlxB6gn1/bp6m7sBU4GfA7h7s7vvoYu3Oy0C5KcfWi0gNWNBl2q3u78O7Gq1+2BtvAp40t2b3H09sJbUZ167BSUIjnQCvBOemQ0GxgJvAX3dfRukwgLok8XSMuHHwF1AssW+rt7moUAl8Iv0kNjPzKyQLt5ud98C/DewCdgG1Lj7S3TxdqcdrI3H/PkWlCBo9wR4XYGZFQHPAF9299ps15NJZvZhYKe7L8h2LZ0sAowDHnT3sUAdJ/5wyGGlx8WvAoYA/YBCM7s+u1Vl3TF/vgUlCNo1AV5XYGY5pELg1+7+bHr3DjM7Of36ycDObNWXAVOAj5jZBlJDfhea2a/o2m2G1N/pCnd/K739NKlg6Ort/iCw3t0r3T0GPAucQ9dvNxy8jcf8+RaUIJgHDDOzIWaWS+rGyows19ThLDVh08+Ble7+wxYvzQA+nf7508DznV1bprj7Pe5e5u6DSf25vuru19OF2wzg7tuBzWZ2WnrXRcAKuni7SQ0JTTKzgvTf94tI3Qvr6u2Gg7dxBjDNzPLMbAgwDJh7RFd290D8Ai4nNRvqu8DXs11Phtp4Lqku4VJgcfrX5aQm9nsFWJP+b89s15qh9l8A/CH9c5dvMzAGmJ/+8/4d0CMg7f434B1gGfBLIK+rtRt4gtQ9kBipf/F/5lBtBL6e/mxbRWpK/yN6P00xISIScEEZGhIRkYNQEIiIBJyCQEQk4BQEIiIBpyAQEQk4BYFIhpnZBftnRRU5HikIREQCTkEgkmZm15vZXDNbbGY/Ta9xsM/MfmBmC83sFTMrTR87xszmmNlSM3tu/9zwZnaqmb1sZkvS55ySvnxRi7UDfp1+KhYz+76ZrUhf57+z1HQJOAWBCGBmI4FPAlPcfQyQAD4FFAIL3X0c8BrwrfQpjwNfdfczgbdb7P81cL+7jyY1B8629P6xwJdJrYcxFJhiZj2BjwKnp6/z75lso8jBKAhEUi4CzgLmmdni9PZQUlNbT08f8yvgXDMrAbq7+2vp/Y8BU82sGOjv7s8BuHuju9enj5nr7hXuniQ19cdgoBZoBH5mZn8H7D9WpFMpCERSDHjM3cekf53m7v/axnGHmpOlremA92tq8XMCiLh7nNQCIs+QWmTkxSMrWaRjKAhEUl4BrjGzPnBgfdhBpP4fuSZ9zHXAm+5eA+w2s/PS+28AXvPU2g8VZnZ1+hp5ZlZwsDdMrxtR4u4zSQ0bjenwVom0QyTbBYgcD9x9hZl9A3jJzEKkZn38AqkFX043swVADan7CJCaBvih9Af9OuDm9P4bgJ+a2bfT1/j4Id62GHjezKKkehP/2MHNEmkXzT4qcghmts/di7Jdh0gmaWhIRCTg1CMQEQk49QhERAJOQSAiEnAKAhGRgFMQiIgEnIJARCTg/j/rO/3Phg8XZgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot history (also known as the loss curve)\n",
    "pd.DataFrame(history.history).plot()\n",
    "plt.ylabel(\"loss\")\n",
    "plt.xlabel(\"epochs\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e7f79fd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.8800667 ]\n",
      " [0.8972591 ]\n",
      " [0.6909491 ]\n",
      " [0.37288734]\n",
      " [0.3041173 ]]\n",
      "[[0.         0.         0.         0.88006669]\n",
      " [0.         0.         0.         0.89725912]\n",
      " [0.         0.         0.         0.69094908]\n",
      " [0.         0.         0.         0.37288734]\n",
      " [0.         0.         0.         0.30411729]]\n",
      "[[101.86644684]\n",
      " [101.98163608]\n",
      " [100.59935885]\n",
      " [ 98.4683452 ]\n",
      " [ 98.00758586]]\n"
     ]
    }
   ],
   "source": [
    "# predict the next values of the test set\n",
    "predictions_scaled = model.predict(X_test)\n",
    "print(predictions_scaled)\n",
    "zeros = np.zeros((5,3))\n",
    "predictions_scaled = np.append(zeros,predictions_scaled,axis=1)\n",
    "print(predictions_scaled)\n",
    "\n",
    "# Re-transform the scaled data to the original format!\n",
    "predictions = sc1.inverse_transform(predictions_scaled)[:,[3]]\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2bd023b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the result\n",
    "predictions_list = [i[0] for i in predictions]\n",
    "\n",
    "predictions_for_plot = [None for i in range(len(df_train))] + predictions_list\n",
    "df_total['prediction'] = predictions_for_plot\n",
    "ax = df_total[['Value','prediction']].plot(ylim=(60,120), title=product, marker='.', markersize=10)\n",
    "ax.set_xlabel(\"index\")\n",
    "ax.set_ylabel(\"product index\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a7dbbc",
   "metadata": {},
   "source": [
    "## Model 4 : LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a641068",
   "metadata": {},
   "source": [
    "### Split in training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "849766bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5 # use 5 previous datapoints to predict the next one.\n",
    "df_length = scaled_df_train.shape[0]\n",
    "X_train = []\n",
    "y_train = []\n",
    "for i in range(n,df_length): # eg if df = [1,2,3,4,5,6,7,...]\n",
    "    X_train.append(scaled_df_train[i-n:i]) # [1,2,3,4,5]\n",
    "    y_train.append(scaled_df_train[i][-1]) # [6] = next one!\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "amount_time_series = X_train.shape[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d43589",
   "metadata": {},
   "source": [
    "### Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4dc53139",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model):\n",
    "    # -------------- Get ready for testing! --------------#\n",
    "\n",
    "    # First get n latest values of the training set to predict the first value of the test set\n",
    "    df = pd.concat([df_train.iloc[-n:], df_test])\n",
    "    x_test_normal = df.values\n",
    "    scaled_test = sc1.transform(x_test_normal)  # scale test data with the scaler of the training data!\n",
    "    X_test = []\n",
    "    for i in range(n, len(df)):\n",
    "        X_test.append(scaled_test[i - n:i])\n",
    "    X_test = np.array(X_test)\n",
    "\n",
    "    # predict the next values of the test set\n",
    "    predictions_scaled = model.predict(X_test)\n",
    "\n",
    "    # Add zeros to yr predcitions, to fix the scaler error.\n",
    "    zeros = np.zeros((n, amount_time_series - 1))\n",
    "    predictions_scaled = np.append(zeros, predictions_scaled, axis=1)\n",
    "\n",
    "    # Re-transform the scaled data to the original format!\n",
    "    predictions = sc1.inverse_transform(predictions_scaled)[:, [3]]\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a192160c",
   "metadata": {},
   "source": [
    "### Make LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "384becd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(amount_neurons,amount_dropout):\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    # add Layer 1 with dropout: deactivate 10% of neurons at random during training to avoid overfitting\n",
    "    model.add(LSTM(amount_neurons, activation='relu', input_shape=(n, amount_time_series)))\n",
    "    model.add(Dropout(amount_dropout))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam',loss='mse')\n",
    "\n",
    "    #-------------- Fit the model on the training set --------------#\n",
    "    model.fit(X_train,y_train,epochs=100)\n",
    "    predictions = predict(model)\n",
    "    mse = mean_squared_error(y_true, predictions.flatten())\n",
    "    print(mse)\n",
    "\n",
    "    return mse, model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c18f1c",
   "metadata": {},
   "source": [
    "## Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f3459075",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search():\n",
    "    grid_params = {'neurons':[10,20,40,50,100],'dropout_percentage':[0.05,0.1,0.2,0.5]}\n",
    "    best_model = {'mse':100,'neurons':0,'dropout_percentage':0} # here we will save our best model in\n",
    "    for i in grid_params['neurons']:\n",
    "        for j in grid_params['dropout_percentage']:\n",
    "            print(f\"neurons: {i}, drop: {j}\")\n",
    "            mse,model = make_model(i,j)\n",
    "            if mse < best_model['mse']:\n",
    "                print('better model found! :)')\n",
    "                best_model['mse'] =  mse\n",
    "                best_model['neurons'] = i\n",
    "                best_model['dropout_percentage'] = j\n",
    "                model.save('best_model')\n",
    "    print(best_model)\n",
    "\n",
    "    best_model = keras.models.load_model('best_model')\n",
    "    return best_model # Best model found includes 20 neurons and a dropout equal to 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff7be0e",
   "metadata": {},
   "source": [
    "## Plotting results of best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9b0a6020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neurons: 10, drop: 0.05\n",
      "Epoch 1/100\n",
      "1/1 [==============================] - 1s 504ms/step - loss: 0.3971\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3773\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3746\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.3685\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.3525\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3501\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3406\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.3450\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3246\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.3339\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3155\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.3120\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.3143\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2971\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2994\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2875\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2971\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2828\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2815\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2697\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2569\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2556\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2549\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2540\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2537\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2383\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2279\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2229\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2209\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2348\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2082\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2158\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2027\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2003\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1974\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1839\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1869\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1819\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1748\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1661\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1651\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1570\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1644\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1573\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1517\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1400\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1418\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1498\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1428\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1424\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1325\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1240\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1150\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1162\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1315\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1037\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1147\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1051\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1105\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1100\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0946\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0976\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0890\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0877\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0816\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0972\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0848\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0848\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0780\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0759\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0751\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0678\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0684\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0988\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0644\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0598\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0714\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0515\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0566\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0626\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0682\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0524\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0459\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0571\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0580\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0410\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0531\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0509\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0464\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0422\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0429\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0366\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0489\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0378\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0399\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0400\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0440\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0446\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0451\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0423\n",
      "14.414077468846099\n",
      "better model found! :)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pjcnudde/miniforge3/envs/MDA/lib/python3.8/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "2022-05-25 16:38:50.060771: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x11ac134f0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neurons: 10, drop: 0.1\n",
      "Epoch 1/100\n",
      "1/1 [==============================] - 0s 392ms/step - loss: 0.3246\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3258\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3238\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3160\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3136\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3225\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2994\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2891\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2906\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2793\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2890\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2714\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2744\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2721\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2626\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2553\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2500\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2452\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2398\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2440\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2358\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2347\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2355\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2301\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2296\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2140\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2097\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2028\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2116\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1964\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1980\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1921\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1793\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1719\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1702\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1683\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1792\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1555\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1712\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1480\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1592\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1459\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1443\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1669\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1508\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1506\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1362\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1506\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1482\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1426\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1373\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1388\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1341\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1416\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1314\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1352\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1260\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1342\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1310\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1424\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1194\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1249\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1279\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1332\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1194\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1162\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1074\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1080\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1195\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1112\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1286\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1085\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1098\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1269\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1040\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1278\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1043\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1070\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1046\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1118\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1091\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1117\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0928\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1025\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1044\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1182\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1022\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0985\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0952\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1025\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1033\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0843\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0967\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0994\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0929\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0961\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0850\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0797\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0847\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0934\n",
      "11.656664882929984\n",
      "better model found! :)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pjcnudde/miniforge3/envs/MDA/lib/python3.8/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x11b78ea00> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neurons: 10, drop: 0.2\n",
      "Epoch 1/100\n",
      "1/1 [==============================] - 0s 314ms/step - loss: 0.3829\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3673\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3755\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3689\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3522\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3523\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2985\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3091\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3323\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3334\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2961\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2829\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3052\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2805\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2505\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2374\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2717\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2650\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2388\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2685\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2237\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2497\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2219\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2028\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2230\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2026\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1874\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1923\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1899\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2333\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1729\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2035\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1993\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1662\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1548\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1466\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1741\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1569\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1483\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1561\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1394\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1420\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1443\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1410\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1464\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1302\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1242\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1219\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1425\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1215\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1118\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1283\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0850\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1110\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1508\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1134\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1215\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1223\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1061\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0925\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0834\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1002\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1211\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0999\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0925\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0784\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1011\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0718\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0980\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0867\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1337\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0982\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0699\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1279\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0934\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0571\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0836\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0763\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0956\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0717\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1081\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0751\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0932\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0802\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0778\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0711\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0862\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0794\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0753\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0675\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0704\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0606\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1052\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0725\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0739\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0820\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0864\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0674\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0712\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0692\n",
      "14.822833359372325\n",
      "neurons: 10, drop: 0.5\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pjcnudde/miniforge3/envs/MDA/lib/python3.8/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 319ms/step - loss: 0.4344\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4272\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4049\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4087\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4228\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4034\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4018\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4044\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4075\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3989\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3712\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3835\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3684\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3581\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3689\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3770\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3587\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3440\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3632\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3465\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3491\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3313\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3333\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3224\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3141\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3220\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3167\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3306\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3050\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3121\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2982\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3073\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3116\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2943\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2928\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2698\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2802\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2743\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2621\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2900\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2739\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2606\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2694\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2718\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2546\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2608\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2367\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2419\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2603\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2514\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2299\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2394\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2312\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2255\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2322\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1945\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2208\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2141\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1927\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2228\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1981\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2231\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1988\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2057\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1761\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1824\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2159\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1551\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1544\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1707\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1840\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1595\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1760\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1838\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1651\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1462\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1581\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1497\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1618\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1457\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1638\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1503\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1602\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1519\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1439\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1564\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1581\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1688\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1581\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1481\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1080\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1402\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1219\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1280\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1362\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1672\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1469\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1462\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1656\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1178\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x11c5054c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pjcnudde/miniforge3/envs/MDA/lib/python3.8/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x11c5054c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.771317873076594\n",
      "better model found! :)\n",
      "INFO:tensorflow:Assets written to: best_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x167277d90> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neurons: 20, drop: 0.05\n",
      "Epoch 1/100\n",
      "1/1 [==============================] - 0s 305ms/step - loss: 0.4921\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4877\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4846\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4814\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4788\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4683\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4552\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4392\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4373\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4361\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4229\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4070\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4059\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4069\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3940\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3918\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3854\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3722\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3748\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3529\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3560\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3506\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3314\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3212\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3205\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3059\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3188\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3010\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2931\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2832\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2827\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2729\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2600\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2574\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2636\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2429\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2399\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2266\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2258\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2226\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2097\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2032\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1858\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1921\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1754\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1873\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1890\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1745\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1572\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1491\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1412\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1382\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1333\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1278\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1194\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1374\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1124\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1165\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1157\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1143\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0997\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1027\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1080\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0964\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0971\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0929\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0991\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1005\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0863\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0992\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0855\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1040\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1040\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0934\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0899\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0763\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0861\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0816\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0850\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0851\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0849\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0840\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0768\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0923\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0792\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0734\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0760\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0805\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0806\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0610\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0673\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0722\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0758\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0811\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0675\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0718\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0687\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0560\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0660\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0597\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x119d659d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pjcnudde/miniforge3/envs/MDA/lib/python3.8/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x119d659d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.351804507763433\n",
      "neurons: 20, drop: 0.1\n",
      "Epoch 1/100\n",
      "1/1 [==============================] - 0s 311ms/step - loss: 0.3366\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3623\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3439\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3260\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3189\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3341\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2943\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3134\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2917\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2756\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2795\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2839\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2800\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2597\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2629\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2559\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2443\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2577\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2350\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2309\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2184\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2097\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2211\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2163\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1951\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2129\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2090\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2123\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1842\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1690\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1701\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1568\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1771\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1565\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1385\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1437\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1403\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1320\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1252\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1140\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1198\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1124\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1114\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1062\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1016\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0991\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0893\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0828\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0874\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0962\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0775\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0722\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0655\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0707\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0663\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0602\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0545\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0558\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0516\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0545\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0513\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0453\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0586\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0533\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0476\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0391\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0583\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0538\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0556\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0442\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0565\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0587\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0574\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0527\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0582\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0420\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0571\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0506\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0487\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0553\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0518\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0443\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0396\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0524\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0464\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0385\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0454\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0413\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0353\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0389\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0412\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0404\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0463\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0419\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0401\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0366\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0496\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0425\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0464\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0440\n",
      "11.889689588458666\n",
      "neurons: 20, drop: 0.2\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pjcnudde/miniforge3/envs/MDA/lib/python3.8/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 314ms/step - loss: 0.2432\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2605\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2641\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2363\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2321\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2151\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1989\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2168\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1871\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1593\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1599\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1652\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1527\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1646\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1572\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1452\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1484\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1214\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1377\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1347\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1109\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1203\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1084\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1043\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1264\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1189\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0928\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0858\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0987\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0813\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1040\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1028\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0729\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0717\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0821\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0968\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0701\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0824\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0929\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0855\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0732\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0650\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0876\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0673\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0833\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0777\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0665\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0641\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0713\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0602\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0677\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0530\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0600\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0891\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0891\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0560\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0741\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0707\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0675\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0661\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0697\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0601\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0580\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0560\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0517\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0610\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0680\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0779\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0842\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0432\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0504\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0471\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0493\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0540\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0428\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0532\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0827\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0509\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0533\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0442\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0552\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0488\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0603\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0672\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0590\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0505\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0524\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0698\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0521\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0412\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0675\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0569\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0368\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0602\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0521\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0612\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0528\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0472\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0481\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0555\n",
      "14.235575052199888\n",
      "neurons: 20, drop: 0.5\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pjcnudde/miniforge3/envs/MDA/lib/python3.8/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 315ms/step - loss: 0.2724\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2544\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2422\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2450\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2122\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2081\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2279\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2107\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2361\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2070\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1788\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1935\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2021\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1895\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1957\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1853\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1710\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1570\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1708\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1536\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1499\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1225\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1432\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1456\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1659\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1436\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1498\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1392\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1216\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1335\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1124\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0975\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1645\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1081\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0959\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1247\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0839\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1101\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0907\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1204\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1235\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0825\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0661\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0743\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0983\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0704\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0871\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1194\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0818\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0691\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0797\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0875\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0721\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0918\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0857\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0838\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1229\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0957\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0851\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1002\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0828\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0711\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0658\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0654\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0651\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1212\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0885\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0601\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0579\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0570\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0763\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0565\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0851\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0730\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0696\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0776\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0536\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0808\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0668\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0412\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1005\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0713\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0783\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0795\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0691\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0518\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0581\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0803\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0493\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0474\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0595\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0843\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0537\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0597\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0651\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0503\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0553\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0511\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0628\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0547\n",
      "12.615941874923356\n",
      "neurons: 40, drop: 0.05\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pjcnudde/miniforge3/envs/MDA/lib/python3.8/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 318ms/step - loss: 0.3317\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3258\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3211\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3117\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3022\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2967\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2875\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2803\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2714\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2622\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2569\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2470\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2417\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2339\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2254\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2205\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2111\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2016\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1962\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1862\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1792\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1709\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1624\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1574\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1426\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1365\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1303\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1216\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1208\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1072\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1033\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0981\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0874\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0830\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0745\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0721\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0659\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0666\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0595\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0585\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0591\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0571\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0609\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0543\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0529\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0605\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0575\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0528\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0541\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0494\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0567\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0514\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0494\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0506\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0433\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0433\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0414\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0439\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0413\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0385\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0365\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0372\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0333\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0407\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0378\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0376\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0336\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0360\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0367\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0398\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0318\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0337\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0288\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0337\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0306\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0318\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0296\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0259\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0322\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0303\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0327\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0308\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0279\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0289\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0333\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0257\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0271\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0293\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0271\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0281\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0285\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0274\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0298\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0314\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0265\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0322\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0279\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0229\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0242\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0283\n",
      "13.908854084007752\n",
      "neurons: 40, drop: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pjcnudde/miniforge3/envs/MDA/lib/python3.8/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 0s 303ms/step - loss: 0.2551\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2384\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2362\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2284\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2156\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2153\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2002\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1956\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1857\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1715\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1693\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1581\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1608\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1414\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1355\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1298\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1188\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1145\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1131\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1026\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0951\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0947\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0863\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0777\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0722\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0738\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0686\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0677\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0675\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0674\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0688\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0579\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0630\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0516\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0572\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0603\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0583\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0570\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0566\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0628\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0573\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0512\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0516\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0493\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0437\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0550\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0437\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0434\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0431\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0462\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0454\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0402\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0448\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0436\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0361\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0376\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0408\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0386\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0361\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0394\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0370\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0406\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0370\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0286\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0352\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0327\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0333\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0355\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0309\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0376\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0320\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0373\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0350\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0318\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0318\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0263\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0325\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0249\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0387\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0304\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0321\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0245\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0261\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0282\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0266\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0251\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0267\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0215\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0303\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0243\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0238\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0302\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0343\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0393\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0243\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0256\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0279\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0311\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0292\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0283\n",
      "12.381880548995454\n",
      "neurons: 40, drop: 0.2\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pjcnudde/miniforge3/envs/MDA/lib/python3.8/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 313ms/step - loss: 0.4463\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4432\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4135\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3913\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3835\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3718\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3383\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3328\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3304\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3058\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2949\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2796\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2754\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2568\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2479\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2396\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2263\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2218\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2031\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1826\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1901\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1763\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1615\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1430\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1487\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1225\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1244\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1118\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1078\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0957\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1099\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0872\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0741\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0878\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0812\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0803\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0650\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0679\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0809\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0731\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0844\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0688\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0724\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0610\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0626\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0700\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0574\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0587\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0625\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0625\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0741\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0588\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0574\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0478\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0415\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0536\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0541\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0500\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0560\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0478\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0452\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0520\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0446\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0515\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0425\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0455\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0515\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0391\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0308\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0432\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0425\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0549\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0332\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0464\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0380\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0382\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0364\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0432\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0395\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0403\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0370\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0330\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0326\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0257\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0462\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0418\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0421\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0424\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0275\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0288\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0371\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0348\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0332\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0391\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0298\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0409\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0348\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0295\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0281\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0302\n",
      "11.842188793533541\n",
      "neurons: 40, drop: 0.5\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pjcnudde/miniforge3/envs/MDA/lib/python3.8/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 317ms/step - loss: 0.3592\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3379\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3322\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3176\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3154\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2987\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2850\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3010\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2976\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2640\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2712\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2890\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2517\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2450\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2217\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2297\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2095\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2007\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1988\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1593\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1864\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1855\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1714\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1736\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1339\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1569\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1267\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1100\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1228\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1046\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1006\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0911\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0829\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0888\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0920\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1031\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0826\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1000\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0908\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0784\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0934\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0641\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0790\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0906\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0824\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0886\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0665\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1144\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0527\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0679\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0666\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0576\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0852\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0644\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0532\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0679\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0576\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0743\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0697\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0436\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0594\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0666\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0545\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0583\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0754\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0789\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0501\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0624\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0560\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0638\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0769\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0473\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0718\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0495\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0686\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0418\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0635\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0580\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0595\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0545\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0610\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0686\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0418\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0512\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0489\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0394\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0622\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0620\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0339\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0442\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0366\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0565\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0349\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0787\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0513\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0494\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0446\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0503\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0477\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0514\n",
      "11.191017713762891\n",
      "neurons: 50, drop: 0.05\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pjcnudde/miniforge3/envs/MDA/lib/python3.8/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 317ms/step - loss: 0.5672\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5338\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5265\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5028\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4869\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4683\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4473\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4355\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4144\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4001\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3835\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3711\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3502\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3367\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3206\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3127\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2973\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2801\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2696\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2587\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2483\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2336\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2267\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2143\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1980\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1955\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1750\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1701\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1588\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1498\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1506\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1296\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1256\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1110\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1030\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0963\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0945\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0893\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0903\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0803\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0820\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0836\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0773\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0736\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0770\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0776\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0828\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0726\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0726\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0678\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0759\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0719\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0702\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0715\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0681\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0654\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0628\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0627\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0606\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0634\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0609\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0659\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0562\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0528\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0581\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0536\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0469\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0556\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0491\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0485\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0430\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0457\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0464\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0416\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0425\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0449\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0436\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0425\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0395\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0402\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0407\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0368\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0388\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0363\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0381\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0392\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0360\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0367\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0339\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0356\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0337\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0336\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0312\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0307\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0330\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0309\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0321\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0356\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0301\n",
      "12.952988189966884\n",
      "neurons: 50, drop: 0.1\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pjcnudde/miniforge3/envs/MDA/lib/python3.8/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 314ms/step - loss: 0.2525\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2394\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2232\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2105\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2003\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1879\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1715\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1572\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1580\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1376\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1388\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1122\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1107\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1011\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0910\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0787\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0732\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0690\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0635\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0555\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0583\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0514\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0554\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0507\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0503\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0510\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0427\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0459\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0460\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0512\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0510\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0485\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0524\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0484\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0415\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0499\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0423\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0351\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0402\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0401\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0389\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0386\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0300\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0364\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0298\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0370\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0386\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0330\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0366\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0335\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0307\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0332\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0386\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0340\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0315\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0321\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0309\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0280\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0322\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0343\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0301\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0305\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0315\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0294\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0330\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0311\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0333\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0282\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0325\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0299\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0333\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0292\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0261\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0311\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0203\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0257\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0321\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0323\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0305\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0296\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0291\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0256\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0295\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0258\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0313\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0262\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0283\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0294\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0290\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0282\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0279\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0320\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0291\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0229\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0294\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0295\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0340\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0288\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0271\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0277\n",
      "10.17727997409419\n",
      "better model found! :)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pjcnudde/miniforge3/envs/MDA/lib/python3.8/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model/assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x11b5c9ac0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neurons: 50, drop: 0.2\n",
      "Epoch 1/100\n",
      "1/1 [==============================] - 0s 307ms/step - loss: 0.3865\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3812\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3770\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3523\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3358\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3317\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3165\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3145\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2879\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2830\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2727\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2590\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2397\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2450\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2196\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2134\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2089\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1958\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1808\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1762\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1600\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1596\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1483\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1336\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1259\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1137\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1066\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0958\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0837\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0771\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0710\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0659\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0677\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0521\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0496\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0497\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0505\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0494\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0600\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0581\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0515\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0609\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0465\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0577\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0557\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0584\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0518\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0482\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0453\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0450\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0453\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0453\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0409\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0422\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0479\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0448\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0404\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0466\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0372\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0500\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0340\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0437\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0484\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0454\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0375\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0466\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0359\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0406\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0435\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0396\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0457\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0485\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0339\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0358\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0359\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0304\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0351\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0435\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0372\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0428\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0346\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0324\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0373\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0309\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0421\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0412\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0289\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0328\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0288\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0325\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0359\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0398\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0291\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0278\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0360\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0318\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0364\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0329\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0347\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0276\n",
      "11.040820616700833\n",
      "neurons: 50, drop: 0.5\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pjcnudde/miniforge3/envs/MDA/lib/python3.8/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 316ms/step - loss: 0.2339\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2146\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2149\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2246\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2158\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2054\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1775\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1748\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1612\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1547\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1726\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1511\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1827\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1267\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1517\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1318\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1360\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1556\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0966\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1177\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1151\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0972\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1060\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0868\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1286\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0985\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0950\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0777\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1026\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0819\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0911\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0815\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0913\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0773\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0941\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0814\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0720\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0716\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0802\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0898\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0809\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0770\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0669\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0925\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0871\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0756\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0851\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0630\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0646\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0603\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0811\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0710\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0836\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0659\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0563\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0669\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0582\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0637\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0630\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0702\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0632\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0611\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0566\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0768\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0350\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0533\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0651\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0764\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0668\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0527\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0891\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0690\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0431\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0614\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0416\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0636\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0552\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0592\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0603\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0503\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0594\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0371\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0457\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0562\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0483\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0624\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0635\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0516\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0608\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0575\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0586\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0451\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0407\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0639\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0492\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0702\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0520\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0543\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0346\n",
      "12.886679908106146\n",
      "neurons: 100, drop: 0.05\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pjcnudde/miniforge3/envs/MDA/lib/python3.8/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 320ms/step - loss: 0.4258\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4069\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3864\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.3730\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.3515\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3340\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.3156\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2980\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2898\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2690\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2519\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2378\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2235\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2088\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1943\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1793\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1690\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1516\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1437\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1277\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1162\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1076\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1011\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0978\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0896\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0848\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0840\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0840\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0851\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0860\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0844\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0833\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0832\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0847\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0810\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0741\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0712\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0664\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0667\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0593\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0587\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0607\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0585\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0575\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0532\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0570\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0524\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0537\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0528\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0544\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0499\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0494\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0445\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0494\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0439\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0406\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0419\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0407\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0394\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0379\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0358\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0373\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0319\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0341\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0385\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0328\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0339\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0327\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0338\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0302\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0331\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0328\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0306\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0325\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0291\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0291\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0302\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0294\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0307\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0291\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0288\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0310\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0287\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0319\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0297\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0287\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0266\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0273\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0274\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0279\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0297\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0270\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0274\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0316\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0308\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0278\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0265\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0292\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0250\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0288\n",
      "11.839394684451737\n",
      "neurons: 100, drop: 0.1\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pjcnudde/miniforge3/envs/MDA/lib/python3.8/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 414ms/step - loss: 0.2904\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2714\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2526\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2382\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2227\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2026\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1871\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1757\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1557\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1396\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1321\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1146\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1019\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0917\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0846\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0809\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0736\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0552\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0636\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0637\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0558\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0652\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0649\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0601\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0584\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0618\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0601\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0544\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0501\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0441\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0489\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0456\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0396\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0435\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0432\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0454\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0375\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0369\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0404\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0352\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0336\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0346\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0376\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0320\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0305\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0285\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0298\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0322\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0361\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0260\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0311\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0316\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0301\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0325\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0300\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0312\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0292\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0271\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0299\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0254\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0252\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0280\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0266\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0271\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0256\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0269\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0241\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0261\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0264\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0289\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0282\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0286\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0252\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0287\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0296\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0278\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0262\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0269\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0306\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0247\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0269\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0260\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0277\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0258\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0258\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0259\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0247\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0249\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0240\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0252\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0250\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0239\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0236\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0249\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0267\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0256\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0252\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0276\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0236\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0265\n",
      "11.006435858165357\n",
      "neurons: 100, drop: 0.2\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pjcnudde/miniforge3/envs/MDA/lib/python3.8/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 318ms/step - loss: 0.4293\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3930\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3768\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3565\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3383\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3113\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2947\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2730\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2436\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2313\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2177\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2011\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1805\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1729\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1612\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1420\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1296\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1123\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1113\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0909\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0848\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0798\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0749\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0723\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0685\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0869\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0804\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0729\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0721\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0693\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0750\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0727\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0720\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0762\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0546\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0701\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0567\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0399\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0571\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0609\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0508\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0476\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0585\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0402\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0372\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0441\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0465\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0489\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0480\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0451\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0447\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0457\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0305\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0434\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0364\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0337\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0368\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0332\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0397\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0364\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0384\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0348\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0349\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0300\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0331\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0357\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0374\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0327\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0344\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0318\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0327\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0356\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0272\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0348\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0301\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0320\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0302\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0343\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0279\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0267\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0358\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0339\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0327\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0320\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0348\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0273\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0323\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0265\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0323\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0330\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0340\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0274\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0299\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0286\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0293\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0273\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0282\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0298\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0222\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0277\n",
      "12.752043594773577\n",
      "neurons: 100, drop: 0.5\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pjcnudde/miniforge3/envs/MDA/lib/python3.8/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 315ms/step - loss: 0.4084\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4187\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3826\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3526\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3284\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3331\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3184\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2798\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2799\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2648\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2306\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2280\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2035\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1954\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1761\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1699\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1522\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1371\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1459\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1136\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1167\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0938\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0887\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0986\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0900\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0743\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0629\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0682\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0812\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0958\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0835\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0678\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0782\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0930\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0795\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0859\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0897\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0757\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0890\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0724\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0519\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0519\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0659\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0637\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0537\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0637\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0554\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0665\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0725\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0525\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0670\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0698\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0601\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0646\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0519\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0433\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0689\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0480\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0434\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0352\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0607\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0440\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0545\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0415\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0499\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0459\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0529\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0386\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0459\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0433\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0463\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0485\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0445\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0333\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0295\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0521\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0456\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0529\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0416\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0314\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0518\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0398\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0364\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0444\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0356\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0496\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0431\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0373\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0358\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0428\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0449\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0455\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0361\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0440\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0538\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0393\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0294\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0468\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0331\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0362\n",
      "12.06634562560066\n",
      "{'mse': 10.17727997409419, 'neurons': 50, 'dropout_percentage': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pjcnudde/miniforge3/envs/MDA/lib/python3.8/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/pjcnudde/miniforge3/envs/MDA/lib/python3.8/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot(model):\n",
    "    # plot the result\n",
    "\n",
    "    predictions = predict(model)\n",
    "    predictions_list = [i[0] for i in predictions]\n",
    "\n",
    "    predictions_for_plot = [None for i in range(len(df_train))] + predictions_list\n",
    "    df_total['prediction'] = predictions_for_plot\n",
    "    ax = df_total[['Value','prediction']].plot(ylim=(60,120), title=product, marker='.', markersize=10)\n",
    "    ax.set_xlabel(\"index\")\n",
    "    ax.set_ylabel(\"product index\")\n",
    "    plt.show()\n",
    "\n",
    "best_model = grid_search()\n",
    "plot(best_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
